// Copyright 2019 The TensorFlow Authors. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

namespace tflite;

// WARNING: This file contains experimental interface and is subject to change.

// This corresponds to the schema version.
file_identifier "M000";
// File extension of any written files.
file_extension "tflitemeta";

enum AssociatedFileType : byte {
  UNKNOWN = 0,
  // Files such as readme.txt
  DESCRIPTIONS = 1,
  // Contains labels that annotate certain axis of the tensor. For example,
  // the label file in image classification. Those labels annotate the
  // the output tensor, such that each value in the output tensor is the
  // probability of that corresponding category specified by the label.
  TENSOR_AXIS_LABELS = 2,
  // Contains labels that tensor values correspond to. For example, in
  // the object detection model, one of the output tensors is the detected
  // classes. And each value in the tensor refers to the index of label in the
  // category label file.
  TENSOR_VALUE_LABELS = 3,
  // The vocab files used in NLP.
  VOCABULARY = 4,
  // Files that translate between languages, for example, the language resource
  // file in Android.
  LOCALIZATION = 5,
}

table AssociatedFile {
  // Name of this file.
  name:string;

  // A description of what the file is.
  description:string;

  // Type of the associated file. There may be special pre/post processing for
  // some types. For example in image classification, a label file of the output
  // will be used to convert object index into string.
  type:AssociatedFileType;
}

// The type of content that a tensor may represent.
enum ContentType : byte {
  UNKNOWN = 0,
  IMAGE = 1,
  VIDEO = 2,
  TEXT = 3,
  AUDIO = 4,
  FEATURE = 5,
}

// The type of color space of an image.
enum ColorSpaceType : byte {
  UNKNOWN = 0,
  RGB = 1,
  BGR = 2,
  YUV = 3,
  HSV = 4,
  GRAYSCALE = 5,
}

table ImageSize {
  width:uint;
  height:uint;
}

table ImageProperties {
  // The color space of the image.
  color_space:ColorSpaceType;

  // Indicates the default value of image width and height if the tensor shape
  // is dynamic. For fixed-size tensor, this size will be consistent with the
  // expected size.
  default_size:ImageSize;
}

// Statistics to describe a tensor.
table Stats {
  // Mean and std are utilized to automatically normalize tensor via
  // tflite.support codegen wrapper. Values are normailzed per-channelly by,
  //   (x - mean) / std.
  // For example, a float MobileNet model will have
  //   mean = 127.5f and std = 127.5f.
  // A quantized MobileNet model will have
  //   mean = 0.0f and std = 1.0f.
  // Per-channel mean of the possible values used in normalization.
  // If there is only one value in mean and std, we'll propogate the value to
  // all channels.
  mean:[float];

  // Per-channel standard dev. of the possible values used in normalization.
  std:[float];

  // Unlike mean and std, max and min are not currently used in tflite.support
  // codegen. They mainly serve as references for users to better understand the
  // model. They can also be used to validate model pre/post processing results.
  // If there is only one value in max and min, we'll propogate the value to
  // all channels.
  // Per-channel maximum value of the tensor.
  max:[float];

  // Per-channel minimum value of the tensor.
  min:[float];
}

// Detailed information of an input or output tensor.
table TensorMetadata {
  // Name of the tensor.
  name:string;

  // A description of the tensor.
  description:string;

  // The type of content that this tensor represents.
  content_type:ContentType;

  // The statistics of the tensor values.
  stats:Stats;

  // Properties that define an image. The section is used when the Content Type
  // is specified as image.
  image_properties:ImageProperties;

  // A list of associated files of this tensor.
  associated_files:[AssociatedFile];
}

table SubGraphMetadata {
  // Name of the subgraph.
  name:string;

  // A description explains details about what the subgraph does.
  description:string;

  // Metadata of all input tensors used in this subgraph.
  input_tensor_metadata:[TensorMetadata];

  // Metadata of all output tensors used in this subgraph.
  output_tensor_metadata:[TensorMetadata];

  // A list of associated files of this subgraph.
  associated_files:[AssociatedFile];
}

table ModelMetadata {
  // Name of the model.
  name:string;

  // Model description in schema.
  description:string;

  // Version of the model that specified by model creators.
  version:string;

  // Noted that, the minimum required TFLite runtime version that the model is
  // compatible with, has already been added as a metadata entry in tflite
  // schema. We'll decide later if we want to move it here, and keep it with
  // other metadata entries.

  // Metadata of all the subgraphs of the model. The 0th is assumed to be the
  // main subgraph.
  subgraph_metadata:[SubGraphMetadata];

  // The person who creates this model.
  author:string;

  // Licenses that may apply to this model.
  license:string;

  // A list of associated files of this model.
  associated_files:[AssociatedFile];
}

root_type ModelMetadata;
